import pandas as pd
import os

def merge_and_clean_datasets():
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å—Ç–∞—Ä—ã–µ –∏ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã."""
    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –æ—á–∏—Å—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö...")

    # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
    old_file_path = 'data/yandmast_obr2.csv'
    new_file_path = 'data/julyaug.csv'
    backup_path = 'data/yandmast_obr2_backup.csv'  # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π

    # 1. –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Å—Ç–∞—Ä–æ–≥–æ —Ñ–∞–π–ª–∞
    if os.path.exists(old_file_path):
        os.rename(old_file_path, backup_path)
        print(f"‚úÖ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞: {backup_path}")

    # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã)
    old_df = pd.read_csv(backup_path, usecols=['study_date', 'inventory_number', 'type_of_service'])
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(old_df):,}")

    # 3. –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º
    new_df = pd.read_csv(new_file_path, usecols=['study_date', 'inventory_number', 'type_of_service'], encoding='cp1251', sep=';')
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –î–û –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è: {len(new_df):,}")
    
    # ‚úÖ‚úÖ‚úÖ –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞—Ç—ã ‚úÖ‚úÖ‚úÖ
    # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–∞—Ç—É –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ DD.MM.YYYY –≤ YYYY-MM-DD
    new_df['study_date'] = pd.to_datetime(new_df['study_date'], format='%d.%m.%Y', errors='coerce')
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ —Å—Ç—Ä–æ–∫—É –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    new_df['study_date'] = new_df['study_date'].dt.strftime('%Y-%m-%d')
    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –¥–∞—Ç–∞ –Ω–µ –±—ã–ª–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞
    new_df = new_df.dropna(subset=['study_date'])
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –ü–û–°–õ–ï –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è: {len(new_df):,}")
    # ‚úÖ‚úÖ‚úÖ –ö–û–ù–ï–¶ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø ‚úÖ‚úÖ‚úÖ

    # 4. –û–±—ä–µ–¥–∏–Ω—è–µ–º
    combined_df = pd.concat([old_df, new_df], ignore_index=True)
    print(f"‚úÖ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è: {len(combined_df):,}")

    # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª (–≤ UTF-8 –¥–ª—è –±—É–¥—É—â–µ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    combined_df.to_csv(old_file_path, index=False, encoding='utf-8')
    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {old_file_path}")

    # 6. (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –£–¥–∞–ª—è–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é, –µ—Å–ª–∏ –≤—Å–µ –ø—Ä–æ—à–ª–æ —É—Å–ø–µ—à–Ω–æ
    # os.remove(backup_path)
    # print("üóë –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —É–¥–∞–ª–µ–Ω–∞.")

if __name__ == "__main__":
    merge_and_clean_datasets()
    print("üéâ –ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å run_pipeline.py")